오늘의목표
1.cnn공부 - 합성곱 계층에서의filter, Padding에 대해 더 알아보기.  
2.resnet공부 - Residual Block과 Skip-Connection 에 대해 더 깊이 알아보기

**합성곱 계층에서의 filter**
CNN에서 filter는 커널(n * m의 행렬)와 같은 의미이다. (mask라고도 불린다.)
filter를 사용하는 이유는 사진에서 feature(특징)를 뽑아내기 위함이다.
- 입력 데이터의 전체 이미지에서, filter를 통해 천제 이미지를 순환하며, 특정 filter모양과 일치할수록 더 큰 값을 가지게 될 것인데, 이는 전체 이미지서 특정 filter와 유사한 모양을 가진 부분에 대한 feature들만 얻게 된다는 것을 의미한다. => 특정 filter에 부합하는 feature정보를 얻는 과정.

**Padding**
cnn구조에서, 합성곱층을 지나게 되면, 합성곱 연산으로 인해서 Feature Map의 크기는 입력데이터보다 크기가 작아지게 된다. 이렇게 크기가 작아지는것을 피하기 위해서 Padding 이라는 방법을 사용할 수 있다.
- zero padding : 입력 데이터(이미지) 주위를 0으로 둘러주는 padding의 방법이다.
	- P : padding layer의 수
	- n : 이미지의 크기가 n * n
	- f : 커널의 크기(filter의 크기)가  f * f
	- (n+2p) * (n+2p) : 패딩된 이미지의 크기
	- ((n + 2p – f + 1) * (n + 2p – f + 1)) :  합성곱층을 지난 출력 이미지의 크기
- padding이 필요한 이유
	- 이미지 데이터의 축소를 막을 수 있다. -  여러번의 계산을 거쳐야 하는데 초반부터 이미지가 너무 작아져버린다면 학습을 별로 하지 못하고 끝나버릴 수 있기 때문에 padding을 통해 이미지의 크기를 조절해줘야한다.
	- 모서리에 있는 중요한 정보를 충분히 활용할 수 있다. - padding을 사용하지 않는 경우, 모서를 학습할 기회가 적어지게 된다. 만약 중요한 정보가 모서리쪽에 있다면, 모델의 성능이 떨어기 때문에 padding을 사용하여 모서리의 정보들도 충분히 학습할 수 있도록 해주어야 한다. 
	![패딩과 모서리~](https://ejkiwi.github.io/lib/media/CNN_Padding_Edge.png)
- Valid Padding과 Same Padding : 각각 순서대로 패딩하지 않는 것, 입력데이터와 출력데이터가 동일하도록 하는 패딩을 뜻한다.

**Residual Block**

**Skip-Connection**