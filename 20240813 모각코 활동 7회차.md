오늘의목표
RESNET 실습 - CIFAR10 이미지 분류
양자화 공부
```
import torch

import torch.nn as nn

import torch.nn.functional as F

import torch.backends.cudnn as cudnn

  
  

# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의

class BasicBlock(nn.Module):

    def __init__(self, in_planes, planes, stride=1):

        super(BasicBlock, self).__init__()

  

        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)

        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)

        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)

  

        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)

        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)

        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)

  

        self.shortcut = nn.Sequential() # identity인 경우

        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우

            self.shortcut = nn.Sequential(

                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),

                nn.BatchNorm2d(planes)

            )

  

    def forward(self, x):

        out = F.relu(self.bn1(self.conv1(x)))

        out = self.bn2(self.conv2(out))

        out += self.shortcut(x) # (핵심) skip connection

        out = F.relu(out)

        return out

  
  

# ResNet 클래스 정의

class ResNet(nn.Module):

    def __init__(self, block, num_blocks, num_classes=10):

        super(ResNet, self).__init__()

        self.in_planes = 64

  

        # 64개의 3x3 필터(filter)를 사용

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)

        self.bn1 = nn.BatchNorm2d(64)

        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)

        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)

        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)

        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)

        self.linear = nn.Linear(512, num_classes)

  

    def _make_layer(self, block, planes, num_blocks, stride):

        strides = [stride] + [1] * (num_blocks - 1)

        layers = []

        for stride in strides:

            layers.append(block(self.in_planes, planes, stride))

            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경

        return nn.Sequential(*layers)

  

    def forward(self, x):

        out = F.relu(self.bn1(self.conv1(x)))

        out = self.layer1(out)

        out = self.layer2(out)

        out = self.layer3(out)

        out = self.layer4(out)

        out = F.avg_pool2d(out, 4)

        out = out.view(out.size(0), -1)

        out = self.linear(out)

        return out

  
  

# ResNet18 함수 정의

def ResNet18():

    return ResNet(BasicBlock, [2, 2, 2, 2])
```

```
import torchvision

import torchvision.transforms as transforms

  

transform_train = transforms.Compose([

    transforms.RandomCrop(32, padding=4),

    transforms.RandomHorizontalFlip(),

    transforms.ToTensor(),

])

  

transform_test = transforms.Compose([

    transforms.ToTensor(),

])

  

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)

test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)

  

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)
```

```
device = 'cuda'

  

net = ResNet18()

net = net.to(device)

  

learning_rate = 0.1

file_name = 'resnet18_cifar10.pth'

  

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)

  
  

def train(epoch):

    print('\n[ Train epoch: %d ]' % epoch)

    net.train()

    train_loss = 0

    correct = 0

    total = 0

  

    for batch_idx, (inputs, targets) in enumerate(train_loader):

        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()

  

        outputs = net(inputs)

        loss = criterion(outputs, targets)

        loss.backward()

  

        optimizer.step()

        train_loss += loss.item()

        _, predicted = outputs.max(1)

  

        total += targets.size(0)

        current_correct = predicted.eq(targets).sum().item()

        correct += current_correct

        if batch_idx % 100 == 0:

            print('\nCurrent batch:', str(batch_idx))

            print('Current batch average train accuracy:', current_correct / targets.size(0))

            print('Current batch average train loss:', loss.item() / targets.size(0))

  

    print('\nTotal average train accuarcy:', correct / total)

    print('Total average train loss:', train_loss / total)

  
  

def test(epoch):

    print('\n[ Test epoch: %d ]' % epoch)

    net.eval()

    loss = 0

    correct = 0

    total = 0

  

    for batch_idx, (inputs, targets) in enumerate(test_loader):

        inputs, targets = inputs.to(device), targets.to(device)

        total += targets.size(0)

  

        outputs = net(inputs)

        loss += criterion(outputs, targets).item()

  

        _, predicted = outputs.max(1)

        correct += predicted.eq(targets).sum().item()

  

    print('\nTotal average test accuarcy:', correct / total)

    print('Total average test loss:', loss / total)

  

    state = {

        'net': net.state_dict()

    }

    if not os.path.isdir('checkpoint'):

        os.mkdir('checkpoint')

    torch.save(state, './checkpoint/' + file_name)

    print('Model Saved!')
```

```
import time

  
  

def adjust_learning_rate(optimizer, epoch):

    lr = learning_rate

    if epoch >= 50:

        lr /= 10

    if epoch >= 100:

        lr /= 10

    for param_group in optimizer.param_groups:

        param_group['lr'] = lr

  

start_time = time.time()

  

for epoch in range(0, 150):

    adjust_learning_rate(optimizer, epoch)

    train(epoch)

    test(epoch)

    print('\nTime elapsed:', time.time() - start_time)
```

양자화 공부
 양자화 : 실수형 변수(floating-point type)를 정수형 변수(integer or fixed point)로 변환하는 과정
 양자화 하는 이유 : 인공지능 모델에 큰 비트수의 자료형을 사용 -> 학습 과정에서 계산량과 필요한 메모리 크기 등이 커지게 됨. -> 학습을 시키기 위해 많은 리소스가 필요해지고, 추론도 오래 걸리는 문제가 발생. 양자화를 통하여 효과적인 모델 최적화를 할 수 있는데, float 타입을 int형으로 줄이면서 용량을 줄일 수 있고 bit 수를 줄임으로써 계산 복잡도도 줄일 수 있음
 Pipeline
	-HuggingFace의 가장 기본 기능으로, 자연어 처리 작업, inference(추론)을 빠르게 할 수 있게 해준다.
	-(hugging face에 대한 내용은 처음 보낸 코랩 파일 가장 위에 있으니 더 알아보고싶으시면 참고하시면 됩니다!)
	-pretrained model(사전학습 모델)을 사용하는 가장 쉬운 방법.
	-사전학습모델이란 : 예를 들어 텍스트 유사도 예측 모델을 만들기 위해서, 감정 분석 문제를 학습했던 모델의 가중치를 활용하는 방법. 즉, 감정 분석 문제를 학습하면서 얻은 언어에 대한 이해를 텍스트 유사도 문제를 학습하는 데 활용하는 방식이다.
pipeline(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, kwargs) 매개변수 설명**
	-task : 어떤 작업을 할것인가? -> 여기에서는 'text-generation' 텍스트 생성 작업을 할거임. ( 그 외 question-answering, translation 등등이 있음 ) 이건 pipeline을 사용할 때 꼭 지정해주어야 함. 나머지것들은 기본으로 지정된 것들이 있기 때문에 따로 필요한 경우만 지정해주면 됨.
	-model : 어떤 모델을 사용할것인가? -> 여기에서는 "meta-llama/Meta-Llama-3-8B-Instruct" 라는 hugging face에서 미리 가져온 모델을 사용.
	-device map : 모델이 어디서(GPU 또는 CPU) 실행되어야할까? -> 여기에서는 "auto" 로, 현재 기기에서 사용가능한 장소를 자동으로 감지하고, GPU가 있다면 이를 우선적으로 사용
	-model_kwargs : 추가로 전달할 매개변수(예를 들어 특정 설정을 변경하는 경우 사용) -> 여기에서는 {"quantization_config": quantization_config} 이라는 quantization(양자화) 에 대한 설정을 포함하구 있음.
```
#준비

!pip install bitsandbytes # 양자화 기법을 사용할 수 있게 해주는 파이썬 모듈 다운로드
!pip install -U bitsandbytes
from transformers import pipeline, BitsAndBytesConfig # BitsAndBytesConfig 허깅페이스에서 양자화를 위한 라이브러리

  

#허깅페이스 로그인("meta-llama/Meta-Llama-3-8B-Instruct"를 사용하기 위함)

from huggingface_hub import login
login("내 TOKEN")

  

#양자화 옵션 설정
#4bit로 되어있긴 하지만, 8bit도 가능.

quantization_config = BitsAndBytesConfig(load_in_4bit=True)  # You can also try load_in_8bit
pipe = pipeline("text-generation", "meta-llama/Meta-Llama-3-8B-Instruct", device_map="auto", model_kwargs={"quantization_config": quantization_config})



#양자화 한 후 실행

chat = [
    {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
    {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]
response = pipe(chat, max_new_tokens=512)
print(response[0]['generated_text'][-1]['content'])
chat.append(
    {"role": "user", "content": "Wait, what's so wild about soup cans?"}
)
response = pipe(chat, max_new_tokens=512)
print(response[0]['generated_text'][-1]['content'])
```