<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[ejkiwi.github.io]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://ejkiwi.github.io/</link><image><url>https://ejkiwi.github.io/lib/media/favicon.png</url><title>ejkiwi.github.io</title><link>https://ejkiwi.github.io/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 23 Jul 2024 13:28:08 GMT</lastBuildDate><atom:link href="https://ejkiwi.github.io/lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 23 Jul 2024 13:28:08 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[20240723 모각코 활동 4회차]]></title><description><![CDATA[ 
 <br>오늘의목표<br>
1.cnn공부 - 정의와 구조 살펴보기<br>
2.resnet공부 - 정의와 구조 살펴보기<br>딥 러닝 : 심층 신경망을 주로 다루는 ai분야. 심층 신경망은 신경망을 여러 계층으로 구성한 것.<br>
기존 신경망의 큰 단점 : 입력 데이터의 구조 고려 안 함. -&gt; 이미지와 같은 공간적 구조를 가지는 데이터 다루기 적합하지 않음.<br>
기존 신경망에서의 단점(공간적 구조 데이터 다루기 어려움)을 극복하기 위해 cnn 등장<br>CNN<br>
합성곱 신경망<br>
-2차원 구조를 고려하는 신경망<br>
-가중치와 바이어스로 이루어진 뉴런으로 구성<br>
- 입력데이터를 받고, 처리한 후 특정한 결과를 출력함.<br>
-입력 계층에 들어온 미가공 이미지 데이터에 해당하는 클래스를 예측하는 것이 목적.<br>
-예측된 클래스는 출력 계층의 결과 값 형태(클래스 점수 변환됨)로 출력됨.<br>
-계층의 종류<br>
1. 입력층<br>
- 미가공 이미지 데이터를 받음.<br>
2. 합성곱층<br>
- 합성곱 연산을 수행함.<br>
- 커널(n  m의 행렬)로 이미지(높이  너비)를 처음부터 끝까지 겹쳐 훑는다. 겹쳐지는 부분의 각 이미지와 원소의 값을 곱해서 모두 더한 값을 출력함.<br>
- 스트라이드 : 커널이 입력을 훑는데, 이 때의 보폭을 뜻함.<br>
- 이 때 출력되는 것(입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과)은 '출력 특성 맵(output feature map)' 이라 함.<br>
- CNN에서는 합성곱 계층의 입출력 데이터를 특성 맵(feature map) 이라 함.<br>
- <img alt="lib/media/cnn1.png" src="docs\lib\media\cnn1.png"><br>
3.ReLU층<br>
- 인공신경망에서 사용되는 활성화함수 f(x) = max(0, x) -&gt; 입력값이 0보다 크면 그 값을 그대로 출력하고, 0 이하면 0을 출력.<br>
4. 풀링층<br>
- 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄임.<br>
- 합성곱 연산과 유사함 (커널과 스트라이드 개념이 존재)<br>
- 최대풀링 : 커널과 겹치는 영역 안에서 최대값을 추출<br>
- 평균풀링 : 커널과 겹치는 영역 안에서 평균값을 추출<br>RESNET<br>
CNN의 한 종류<br>
-신경망의 깊이가 깊어짐에 따라 발생하는 훈련 문제를 해결하기 위해 '잔여학습'이라는 개념을 도입함.<br>
- 훈련 문제 : 기존 모델들은 레이어를 깊게 쌓을수록 더 성능이 좋아질 것이라고 예상했지만 실제로는 20층 이상부터 성능이 낮아지는 현상이 발생.<br>
- 잔여학습 : 스킵연결(입력값이 일정층들을 건너뛰어서 출력에 더할 수 있게 하는 역할) -&gt; 기존신경망은 k번째 층과 (i+1)번째 층의 연결로 이루어져있는데, resnet은 (i+r)층의 연결을 허용(shortcut connection).<br>
- <img alt="lib/media/resnet.png" src="docs\lib\media\resnet.png"><br>
-최대 152개 층까지 쌓을 수 있게 됨.<br>
<img alt="cnn2.png" src="docs\lib\media\cnn2.png">]]></description><link>20240723-모각코-활동-4회차.html</link><guid isPermaLink="false">20240723 모각코 활동 4회차.md</guid><pubDate>Tue, 23 Jul 2024 13:24:43 GMT</pubDate><enclosure url="docs\lib\media\cnn1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="docs\lib\media\cnn1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[20240707 모각코 활동 1회차]]></title><description><![CDATA[ 
 <br>오늘의 목표<br>
1.모각코 활동 동안 공부할 주제 전체적으로 톺아보기<br>
2.팀원들과 친해지기<br>파이토치<br>
<br>python을 바탕으로 제작된, 딥러닝과  인공지능 분야에서 주로 활용되는 라이브러리
<br>pytorch의 연산은 tensor를 기본으로 하여 작동
<br>tensor : 파이토치의 기본 데이터 타입. 배열이나 행렬과 유사한 구조(다차원 배열)이다.
<br>파이토치를 기반으로 구성된 모델은 학습을 위한 그래디언트를 자동으로 계산한다. -&gt; 자동 미분
<br>그래디언트 : 벡터 미분의 결과 (=함수의 기울기, 각 변수에 대한 변화율)
<br>선배님의 프로젝트<br>
<br><a data-tooltip-position="top" aria-label="https://github.com/b-re-w/2024-1_BPL_STalk_Model_Research" rel="noopener" class="external-link" href="https://github.com/b-re-w/2024-1_BPL_STalk_Model_Research" target="_blank">2024-1_BPL_STalk_Model_Research</a>
<br>CNN 모델<br>
<br>2차원 데이터 (이미지 등)의 패턴을 인식하고 분석하는 데 사용되는 딥러닝 모델.
<br>여러개의 층으로 구성됨.
<br>인간의 시신경 구조를 모방한 구조임
<br>이미지의 
<br>RESNET 모델<br>
<br>CNN 모델에 잔차 연결 개념을 도입한 것.
<br>잔차 연결 : 각 층의 출력을 다음 층으로 직접 보내는 대신에, 입력을 더한 뒤 다음 층으로 전달하는 연결.
]]></description><link>20240707-모각코-활동-1회차.html</link><guid isPermaLink="false">20240707 모각코 활동 1회차.md</guid><pubDate>Mon, 15 Jul 2024 07:48:10 GMT</pubDate></item><item><title><![CDATA[20240709 모각코 활동 2회차]]></title><description><![CDATA[ 
 <br>오늘의 목표<br>
1.파이토치 공부하기 - youtube에 있는 파이토치 설명 강좌(<a rel="noopener" class="external-link" href="https://youtube.com/playlist?list=PLS8gIc2q83Oit-utRso2iblvt00fZOw85&amp;si=i0CZi4e5g_dVJ3dx" target="_blank">https://youtube.com/playlist?list=PLS8gIc2q83Oit-utRso2iblvt00fZOw85&amp;si=i0CZi4e5g_dVJ3dx</a>) 1,2,3강 들으며 공부<br>
2.선배님의 프로젝트 코드 절반 분석하기 - whisper 부분<br>파이토치<br>
al분야에서 google tensorflow와 함께 딥러닝 모델을 구축하고 학습하는 데 가장 많이 사용되고 있는 오픈 소스 기반의 딥러닝 프레임워크임.<br>
<br>오픈소스 : 개방형 협업을 장려하는 소프트웨어 개발 모델
<br>프레임워크 : 소프트웨어 개발에 있어 하나의 뼈대와 같은 역할을 하는 것으로, 목적에 필요한 것을 고민할 필요 없이 이용할 수 있도록 일괄로 가져다 쓰도록 만들어 놓은 구조화된 틀임.<br>
텐서 : 파이토치의 기본 데이터 타입
<br>배열이나 행렬과 유사한 자료 구조이다
<br>일반적으로는 1차원 - 벡터 , 2차원 - 행렬, 3차원 이상 - 벡터 이지만, 파이토치에서는 입력과 출력 그리고 학습에 필요한모든 데이터들을 모두 텐서 데이터타입으로 정의하고 있다.
<br>텐서의 속성으로는 모양,자료형,저장되는 위치가 있다
<br>보통 저장되는 위치는 cpu인데, gpu를 사용할 수 있다면, .to("cuda")를 사용해서 텐서를 gpu로 이동시킬 수 있다.

<br>gpu : 컴퓨터 그래픽을 처리하는 장치로 그래픽 카드를 구성하는 가장 중요한 핵심 요소.


<br>1.파이썬의 리스트 데이터로부터 직접 텐서를 만들 수 있다.<br>
- listdata = [[10,20],[30,40]] 	tensor1 = torch.Tensor(listdata)`
<br>2.파이썬의 넘파이 데이터로부터 직접 텐서를 만들 수도 있다.(넘파이로만들어진건 보통 int로 생성되기때문에 원래 데이터가 float의 형태인 경우, 캐스팅해주는 작업이 필요하기도 하다.)
<br>3.파이썬의 랜덤 데이터로부터 직접 텐서를 만들 수도 있다.<br>
- tensor3 = torch.rand(2,2) -&gt; rand()메서드는 0~1사이의 균일 분포 랜덤값을 생성함 ( randn()메서드는 정규분포를 가지는 랜덤값을 생성 )
<br>텐서를 넘파이로 바꿀 수도 있다.<br>
- tensor.numpy()
<br>인덱싱과 슬라이싱이 가능하다
<br>elment-wise product 연산 
<br>matrix multiplication 연산 (행렬곱)
<br>텐서를 합칠 수 있다. Tensor Concatenate (dim=0 세로, dim=1 가로)<br>
파이토치 딥러닝 모델 구조 :<br>
1.데이터정의<br>
- 기본 데이터타입인 TENSOR로 생성해야함.<br>
- TensorDataset(x_train,y_train) : 텐서 데이터셋 생성<br>
- DataLoader(dataset, batch_size, shuffle) : 미니 배치 학습과 데이터 셔플, 멀티 프로세싱 등을 간단하게 수행할 수 있음.<br>
- 미니 배치 학습 : 전체 데이터를 n등분 하여 각각의 학습 데이터를 배치 방식으로 학습시키는 것.<br>
- 데이터 셔플 : train데이터와test데이터 간의 동일한 분포를 가지도록 섞어는 것.<br>
- 멀티 프로세싱 : 여러 작업을 별도의 프로세스를 생성 후 병렬처리를 하는 과정을 거치기 때문에 더 빠르게 결과를 얻을 수 있다.<br>
2.모델구축<br>
- nn.Module을 상속받는 class를 생성하여 정의하는 것이 일반적이다.<br>
- 클래스 속 __init__함수에서 계층(신경망 모델을 구성하는)을 정의.<br>
- 클래스 속 forward 함수에서 신경망에 데이터 전달하기를 수하고, 결과값을 리턴함<br>
3.피드포워드<br>
- 모델 학습을 위해서는 피드 포워드 계산값과 정답의 차이 계산이 필요  -&gt; 이 계산을 위해서는 손실함수와 옵티마이저가 필요함.<br>
- 손실함수 : MSE 등<br>
- 옵티마이저 : SDG, ADAM<br>
4.손실함수계산<br>
- nn.MSELoss(model(x_train),y_train) : 피드포워드 계산 값과 정답과의 오차 계산.<br>
- 이 때, model에 데이터를 전달하면 model 클래스 안에 있는 forward()함수자동으로 forward()함수를 호출하기 때문에 우리가 따로 호출해줄 필요가 없다.<br>
5.모델학습<br>
-역전파 코드 : 학습이 진행됨에 따라서 모델 파라미터(가중치와 바이어스)를 업데이트하면서 최적화 시킨다<br>
- optimizer.zero.grad()<br>
- loss.backward()<br>
- optimizer.step()<br>
- 모델(model) : 각 층을 포함하고 있는 인공신경망 그 자체 (이를 레고처럼 순차적으로 쌓기 -&gt; CNN, RNN 등 다양한 모델 구축 가능)<br>
- 3&gt;4&gt;5의 반복 -&gt; 딥러닝 학습<br>
- 손실함수가 최소가 될 때까지 모델 파라미터(가중치, 바이어스) 값을 찾아감.
<br>선배님 프로젝트 분석 - whisper<br>
1.from faster_whisper import WhisperModel<br>
2.def get_whisper() :  	 3.   model_size = "medium"  #@param ['tiny', 'base', 'small', 'medium', 'large', 'large-v2', 'large-v3'] 	 4.   compute_type = "int8"  #@param ['float16', 'int8']<br>
5.   return WhisperModel(model_size, device=DEVICE, cpu_threads=12, compute_type=compute_type).transcribe<br>1: faster_whisper 에서 WhisperModel 모듈 불러오기<br>
2: get_whisper 라는 이름의 함수 설정하기<br>
3: model_size는 "medium"이다. model_size가 가질 수 있는 옵션으로는 "tiny","base","small","medium","large","large-v3" 이 있다. -&gt; model_size는 모델의 크기를 뜻한다.<br>
4: compute_type은 "int8"이다. compute_type이 가질 수 있는 옵션으로는 "float16","int8"이 있다. -&gt; compute_type은 계산 유형을 뜻한다.<br>
5: WhisperModel은 4가지의 매개변수를 사용하는데, 여기에서 model_size는 앞서 정한 크기와 같고, device는 모델이 실행될 장치를 지정한다. cpu_threads는 CPU의 스레드 수를 뜻한다. compute_type또한 앞서 정한 계산 유형과 같다. 이 때 .transcribe는 모델의 음성 인식 기능을 호출해서 음성을 텍스트로 변환해준다.]]></description><link>20240709-모각코-활동-2회차.html</link><guid isPermaLink="false">20240709 모각코 활동 2회차.md</guid><pubDate>Mon, 15 Jul 2024 06:27:57 GMT</pubDate></item><item><title><![CDATA[20240716 모각코 활동 3회차]]></title><description><![CDATA[ 
 <br>오늘의 목표<br>
1.파이토치 공부하기  - 실습해보기<br>
2.선배님의 프로젝트 코드 절반 분석하기 - resnet 부분<br>파이토치 실습<br>import torch #파이토치 불러오기
from torch import nn #토치에서 nn 불러오기
  

#텐서 형태로 train데이터 가져오기
x_train = torch.Tensor([1,2,3,4,5,6]).view(6,1)
y_train = torch.Tensor([3,6,9,12,15,18]).view(6,1)

  
#MyNeuralNetwork 클래스 만들기. nn.Module이 부모클래스가 됨.
class MyNeuralNetwork(nn.Module):
&nbsp; def __init__(self):
&nbsp; &nbsp; super().__init__()
&nbsp; &nbsp; self.linear_relu_stack = nn.Sequential(nn.Linear(1,1))

&nbsp; def forward(self, x):
&nbsp; &nbsp; logits = self.linear_relu_stack(x)
&nbsp; &nbsp; return logits


#모델
model = MyNeuralNetwork()
#손실함수
loss_function = nn.MSELoss()
#옵티마이저
optimizer = torch.optim.SGD(model.parameters(),lr=1e-2)

nums_epoch = 2000


#학습시키기
for epoch in range(nums_epoch + 1):
&nbsp; prediction = model(x_train)
&nbsp; loss = loss_function(prediction, y_train)

&nbsp; optimizer.zero_grad()
&nbsp; loss.backward()
&nbsp; optimizer.step()

&nbsp; if epoch % 100 == 0:
&nbsp; &nbsp; print('epoch = ', epoch, 'current loss = ', loss.item())
Copy<br>#예측하기
x_test = torch.Tensor([8,9,10,11]).view(4,1)
pred = model(x_test)
pred
Copy<br>선배님의 프로젝트 코드<br> def get_resnet152():
    model_id = "Wespeaker/wespeaker-voxceleb-resnet152-LM"
    model_name = model_id.replace("Wespeaker/wespeaker-", "").replace("-", "_")
 
    root_dir = hf_hub_download(model_id, filename=model_name+".onnx").replace(model_name+".onnx", "")

    import os
    if not os.path.isfile(root_dir+"avg_model.pt"):
        os.rename(hf_hub_download(model_id, filename=model_name+".pt"), root_dir+"avg_model.pt")
    if not os.path.isfile(root_dir+"config.yaml"):
        os.rename(hf_hub_download(model_id, filename=model_name+".yaml"), root_dir+"config.yaml")

    resnet = wespeaker.load_model_local(root_dir)

    #print("Compile model for the NPU")
    #resnet.model = intel_npu_acceleration_library.compile(resnet.model)

    def resnet152(ado, sample_rate=None):
        if isinstance(ado, str):
            return resnet.recognize(ado)
        else:
            return recognize(resnet, ado, sample_rate)

    resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)

    return resnet152
Copy<br>분석<br>
def getresnet152():<br>
get_resnet 152 라는 이름의 함수를 정의<br>
model_id = "Wespeaker/wespeaker-voxceleb-resnet152-LM"<br>
model_id라는 변수에 "Wespeaker/wespeaker-voxceleb-resnet152-LM"를 지정. 아마  모델 아이디에 모델의 이름을 저장한 것일 것.<br>
moldel_name = model.id.replace("Wespeaker/wespeaker-",").replace("-", " ")<br>
model_name이라는 변수를 만들어서, model_id를 약간 변형시킨 이름으로 지정해줌. "voxceleb_resnet152_LM"이 될 것.<br>
root_dir = hf_hub_download(model_id, filename = model_name+" .onnx").replace(model_name+" .onnx", "")<br>
hf_hub_download : 이건 함수임. 함수를 사용해서 모델 파일을 다운로드하고, 다운로드한 파일을 root_dir변수에 저장함.<br>
import os<br>
os 모듈을 가져옴<br>
if not os.path.isfile(root_dir+"avg_model.pt"):<br>
os.rename(hf_hub_download(model_id, filename=model_name+".pt"), root_dir+"avg_model.pt")<br>
만약 avg_model.pt이름을 가진 파일이 없다면, 모델의 pt파일을 다운로드 한 뒤 이름을 avg_model.pt로 바꾸어서 root_dir 변수에 저장함.<br>
if not os.path.isfile(root_dir+"config.yaml"):<br>
os.rename(hf_hub_download(model_id, filename=model_name+".yaml"), root_dir+"config.yaml")<br>
앞 코드와 같은 느낌인데, 만약 config.yaml파일이 없으면 모델의 yaml파일을 다운로드 한 뒤 이름을 바꾸어서 root_dir변수에 저장함.<br>
resnet = wespeaker.load_model_local(root_dir)<br>
resnet이라는 변수를 지정해줄건데, wespeaker 라이브러리의 load_model_local 함수를 사용할거임. 이 때 root_dir에 있는 파일들을 불러오게 됨.<br>
def resnet152(ado, sample_rate=None):<br>
if isinstance(ado, str):<br>
return resnet.recognize(ado)<br>
else:<br>
return recognize(resnet, ado, sample_rate)<br>
resnet152라는 함수를 정의해주는데, 이 함수는 입력으로 ado를 받음.<br>
ado가 문자열이라면  resnet.recognize(ado)를 리턴하고<br>
그렇지 않다면  recognize(resnet, ado, sample_rate)을 리턴함.<br>
resnet152.__dict__['register'] = lambda *args, **kwargs: resnet.register(*args, **kwargs)<br>
resnet152라는 함수에 register라는 기능을 추가<br>
return resnet152<br>
get_resnet152라는 함수는 resnet152를 반환함.<br>resnet152 = get_resnet152()
print("INFO: ResNet152 Ready -", resnet152)
Copy<br>분석<br>
resnet152 = get_resnet152()<br>
get_resnet152함수를 가져와서 resnet152함수에 저장함<br>
print("INFO: ResNet152 Ready -", resnet152)<br>
모델이 준비되었다는 메시지를 출력한 뒤, resnet152를 출력함.]]></description><link>20240716-모각코-활동-3회차.html</link><guid isPermaLink="false">20240716 모각코 활동 3회차.md</guid><pubDate>Tue, 16 Jul 2024 08:16:09 GMT</pubDate></item><item><title><![CDATA[20240730 모각코 활동 5회차]]></title><description><![CDATA[ 
 <br>오늘의목표]]></description><link>20240730-모각코-활동-5회차.html</link><guid isPermaLink="false">20240730 모각코 활동 5회차.md</guid><pubDate>Mon, 15 Jul 2024 07:54:50 GMT</pubDate></item><item><title><![CDATA[20240806 모각코 활동 6회차]]></title><description><![CDATA[ 
 <br>오늘의목표]]></description><link>20240806-모각코-활동-6회차.html</link><guid isPermaLink="false">20240806 모각코 활동 6회차.md</guid><pubDate>Mon, 15 Jul 2024 07:54:55 GMT</pubDate></item><item><title><![CDATA[20240813 모각코 활동 7회차]]></title><description><![CDATA[ 
 <br>오늘의목표]]></description><link>20240813-모각코-활동-7회차.html</link><guid isPermaLink="false">20240813 모각코 활동 7회차.md</guid><pubDate>Mon, 15 Jul 2024 07:55:03 GMT</pubDate></item><item><title><![CDATA[모.구.모.구 모각코 활동]]></title><description><![CDATA[ 
 <br>팀 모각코 목표 : 1. 절대 포기하지 않기, 2. 모르는 거 그냥 넘어가지 않기<br>나의 모각코 활동 다짐 : 활동 계획을 완벽히 마무리 할 수 있도록 노력하겠습니다!<br>나의 모각코 활동 계획<br>
<br>7월 7일

<br>모각코 활동 동안 공부할 주제 전체적으로 톺아보기, 팀원들과 친해지기


<br>7월 9일, 7월 16일

<br>파이토치 사용 익히기
<br>선배님 프로젝트의 레포지토리에 있는 코드 분석해보며 공부하기


<br>7월 23일, 7월 30일, 8월 6일, 8월 13일

<br>CNN 구조 공부하기
<br>RESNET 구조 공부하기


]]></description><link>모.구.모.구-모각코-활동.html</link><guid isPermaLink="false">모.구.모.구 모각코 활동.md</guid><pubDate>Fri, 05 Jul 2024 08:47:48 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Tue, 23 Jul 2024 13:03:33 GMT</pubDate></item></channel></rss>